'use strict';

var zodToJsonSchema = require('zod-to-json-schema');
var child_process = require('child_process');
var stream = require('stream');
var backendPluginApi = require('@backstage/backend-plugin-api');
var errors = require('@backstage/errors');
var fs = require('fs-extra');
var path = require('path');
var git = require('isomorphic-git');
var http = require('isomorphic-git/http/node');
var fs$1 = require('fs');
var globby = require('globby');
var limiterFactory = require('p-limit');

function _interopDefaultCompat (e) { return e && typeof e === 'object' && 'default' in e ? e : { default: e }; }

var zodToJsonSchema__default = /*#__PURE__*/_interopDefaultCompat(zodToJsonSchema);
var fs__default = /*#__PURE__*/_interopDefaultCompat(fs);
var path__default = /*#__PURE__*/_interopDefaultCompat(path);
var git__default = /*#__PURE__*/_interopDefaultCompat(git);
var http__default = /*#__PURE__*/_interopDefaultCompat(http);
var globby__default = /*#__PURE__*/_interopDefaultCompat(globby);
var limiterFactory__default = /*#__PURE__*/_interopDefaultCompat(limiterFactory);

const createTemplateAction = (action) => {
  const inputSchema = action.schema?.input && "safeParseAsync" in action.schema.input ? zodToJsonSchema__default.default(action.schema.input) : action.schema?.input;
  const outputSchema = action.schema?.output && "safeParseAsync" in action.schema.output ? zodToJsonSchema__default.default(action.schema.output) : action.schema?.output;
  return {
    ...action,
    schema: {
      ...action.schema,
      input: inputSchema,
      output: outputSchema
    }
  };
};

async function executeShellCommand(options) {
  const {
    command,
    args,
    options: spawnOptions,
    logStream = new stream.PassThrough()
  } = options;
  await new Promise((resolve, reject) => {
    const process = child_process.spawn(command, args, spawnOptions);
    process.stdout.on("data", (stream) => {
      logStream.write(stream);
    });
    process.stderr.on("data", (stream) => {
      logStream.write(stream);
    });
    process.on("error", (error) => {
      return reject(error);
    });
    process.on("close", (code) => {
      if (code !== 0) {
        return reject(
          new Error(`Command ${command} failed, exit code: ${code}`)
        );
      }
      return resolve();
    });
  });
}

async function fetchContents(options) {
  const {
    reader,
    integrations,
    baseUrl,
    fetchUrl = ".",
    outputPath,
    token
  } = options;
  const fetchUrlIsAbsolute = isFetchUrlAbsolute(fetchUrl);
  if (!fetchUrlIsAbsolute && baseUrl?.startsWith("file://")) {
    const basePath = baseUrl.slice("file://".length);
    const srcDir = backendPluginApi.resolveSafeChildPath(path__default.default.dirname(basePath), fetchUrl);
    await fs__default.default.copy(srcDir, outputPath);
  } else {
    const readUrl = getReadUrl(fetchUrl, baseUrl, integrations);
    const res = await reader.readTree(readUrl, { token });
    await fs__default.default.ensureDir(outputPath);
    await res.dir({ targetDir: outputPath });
  }
}
async function fetchFile(options) {
  const {
    reader,
    integrations,
    baseUrl,
    fetchUrl = ".",
    outputPath,
    token
  } = options;
  const fetchUrlIsAbsolute = isFetchUrlAbsolute(fetchUrl);
  if (!fetchUrlIsAbsolute && baseUrl?.startsWith("file://")) {
    const basePath = baseUrl.slice("file://".length);
    const src = backendPluginApi.resolveSafeChildPath(path__default.default.dirname(basePath), fetchUrl);
    await fs__default.default.copyFile(src, outputPath);
  } else {
    const readUrl = getReadUrl(fetchUrl, baseUrl, integrations);
    const res = await reader.readUrl(readUrl, { token });
    await fs__default.default.ensureDir(path__default.default.dirname(outputPath));
    const buffer = await res.buffer();
    await fs__default.default.outputFile(outputPath, buffer);
  }
}
function isFetchUrlAbsolute(fetchUrl) {
  let fetchUrlIsAbsolute = false;
  try {
    new URL(fetchUrl);
    fetchUrlIsAbsolute = true;
  } catch {
  }
  return fetchUrlIsAbsolute;
}
function getReadUrl(fetchUrl, baseUrl, integrations) {
  if (isFetchUrlAbsolute(fetchUrl)) {
    return fetchUrl;
  } else if (baseUrl) {
    const integration = integrations.byUrl(baseUrl);
    if (!integration) {
      throw new errors.InputError(`No integration found for location ${baseUrl}`);
    }
    return integration.resolveUrl({
      url: fetchUrl,
      base: baseUrl
    });
  }
  throw new errors.InputError(
    `Failed to fetch, template location could not be determined and the fetch URL is relative, ${fetchUrl}`
  );
}

function isAuthCallbackOptions(options) {
  return "onAuth" in options;
}
class Git {
  constructor(config) {
    this.config = config;
    this.onAuth = config.onAuth;
    this.headers = {
      "user-agent": "git/@isomorphic-git",
      ...config.token ? { Authorization: `Bearer ${config.token}` } : {}
    };
  }
  headers;
  async add(options) {
    const { dir, filepath } = options;
    this.config.logger?.info(`Adding file {dir=${dir},filepath=${filepath}}`);
    return git__default.default.add({ fs: fs__default.default, dir, filepath });
  }
  async addRemote(options) {
    const { dir, url, remote, force } = options;
    this.config.logger?.info(
      `Creating new remote {dir=${dir},remote=${remote},url=${url}}`
    );
    return git__default.default.addRemote({ fs: fs__default.default, dir, remote, url, force });
  }
  async deleteRemote(options) {
    const { dir, remote } = options;
    this.config.logger?.info(`Deleting remote {dir=${dir},remote=${remote}}`);
    return git__default.default.deleteRemote({ fs: fs__default.default, dir, remote });
  }
  async checkout(options) {
    const { dir, ref } = options;
    this.config.logger?.info(`Checking out branch {dir=${dir},ref=${ref}}`);
    return git__default.default.checkout({ fs: fs__default.default, dir, ref });
  }
  async branch(options) {
    const { dir, ref } = options;
    this.config.logger?.info(`Creating branch {dir=${dir},ref=${ref}`);
    return git__default.default.branch({ fs: fs__default.default, dir, ref });
  }
  async commit(options) {
    const { dir, message, author, committer } = options;
    this.config.logger?.info(
      `Committing file to repo {dir=${dir},message=${message}}`
    );
    return git__default.default.commit({ fs: fs__default.default, dir, message, author, committer });
  }
  /** https://isomorphic-git.org/docs/en/clone */
  async clone(options) {
    const { url, dir, ref, depth, noCheckout } = options;
    this.config.logger?.info(`Cloning repo {dir=${dir},url=${url}}`);
    try {
      return await git__default.default.clone({
        fs: fs__default.default,
        http: http__default.default,
        url,
        dir,
        ref,
        singleBranch: true,
        depth: depth ?? 1,
        noCheckout,
        onProgress: this.onProgressHandler(),
        headers: this.headers,
        onAuth: this.onAuth
      });
    } catch (ex) {
      this.config.logger?.error(`Failed to clone repo {dir=${dir},url=${url}}`);
      if (ex.data) {
        throw new Error(`${ex.message} {data=${JSON.stringify(ex.data)}}`);
      }
      throw ex;
    }
  }
  /** https://isomorphic-git.org/docs/en/currentBranch */
  async currentBranch(options) {
    const { dir, fullName = false } = options;
    return git__default.default.currentBranch({ fs: fs__default.default, dir, fullname: fullName });
  }
  /** https://isomorphic-git.org/docs/en/fetch */
  async fetch(options) {
    const { dir, remote = "origin", tags = false } = options;
    this.config.logger?.info(
      `Fetching remote=${remote} for repository {dir=${dir}}`
    );
    try {
      await git__default.default.fetch({
        fs: fs__default.default,
        http: http__default.default,
        dir,
        remote,
        tags,
        onProgress: this.onProgressHandler(),
        headers: this.headers,
        onAuth: this.onAuth
      });
    } catch (ex) {
      this.config.logger?.error(
        `Failed to fetch repo {dir=${dir},remote=${remote}}`
      );
      if (ex.data) {
        throw new Error(`${ex.message} {data=${JSON.stringify(ex.data)}}`);
      }
      throw ex;
    }
  }
  async init(options) {
    const { dir, defaultBranch = "master" } = options;
    this.config.logger?.info(`Init git repository {dir=${dir}}`);
    return git__default.default.init({
      fs: fs__default.default,
      dir,
      defaultBranch
    });
  }
  /** https://isomorphic-git.org/docs/en/merge */
  async merge(options) {
    const { dir, theirs, ours, author, committer } = options;
    this.config.logger?.info(
      `Merging branch '${theirs}' into '${ours}' for repository {dir=${dir}}`
    );
    return git__default.default.merge({
      fs: fs__default.default,
      dir,
      ours,
      theirs,
      author,
      committer
    });
  }
  async push(options) {
    const { dir, remote, remoteRef, force } = options;
    this.config.logger?.info(
      `Pushing directory to remote {dir=${dir},remote=${remote}}`
    );
    try {
      return await git__default.default.push({
        fs: fs__default.default,
        dir,
        http: http__default.default,
        onProgress: this.onProgressHandler(),
        remoteRef,
        force,
        headers: this.headers,
        remote,
        onAuth: this.onAuth
      });
    } catch (ex) {
      this.config.logger?.error(
        `Failed to push to repo {dir=${dir}, remote=${remote}}`
      );
      if (ex.data) {
        throw new Error(`${ex.message} {data=${JSON.stringify(ex.data)}}`);
      }
      throw ex;
    }
  }
  /** https://isomorphic-git.org/docs/en/readCommit */
  async readCommit(options) {
    const { dir, sha } = options;
    return git__default.default.readCommit({ fs: fs__default.default, dir, oid: sha });
  }
  /** https://isomorphic-git.org/docs/en/remove */
  async remove(options) {
    const { dir, filepath } = options;
    this.config.logger?.info(
      `Removing file from git index {dir=${dir},filepath=${filepath}}`
    );
    return git__default.default.remove({ fs: fs__default.default, dir, filepath });
  }
  /** https://isomorphic-git.org/docs/en/resolveRef */
  async resolveRef(options) {
    const { dir, ref } = options;
    return git__default.default.resolveRef({ fs: fs__default.default, dir, ref });
  }
  /** https://isomorphic-git.org/docs/en/log */
  async log(options) {
    const { dir, ref } = options;
    return git__default.default.log({
      fs: fs__default.default,
      dir,
      ref: ref ?? "HEAD"
    });
  }
  onAuth;
  onProgressHandler = () => {
    let currentPhase = "";
    return (event) => {
      if (currentPhase !== event.phase) {
        currentPhase = event.phase;
        this.config.logger?.info(event.phase);
      }
      const total = event.total ? `${Math.round(event.loaded / event.total * 100)}%` : event.loaded;
      this.config.logger?.debug(`status={${event.phase},total={${total}}}`);
    };
  };
  static fromAuth = (options) => {
    if (isAuthCallbackOptions(options)) {
      const { onAuth, logger: logger2 } = options;
      return new Git({ onAuth, logger: logger2 });
    }
    const { username, password, token, logger } = options;
    return new Git({ onAuth: () => ({ username, password }), token, logger });
  };
}

async function initRepoAndPush(input) {
  const {
    dir,
    remoteUrl,
    auth,
    logger,
    defaultBranch = "master",
    commitMessage = "Initial commit",
    gitAuthorInfo
  } = input;
  const git = Git.fromAuth({
    ...auth,
    logger
  });
  await git.init({
    dir,
    defaultBranch
  });
  await git.add({ dir, filepath: "." });
  const authorInfo = {
    name: gitAuthorInfo?.name ?? "Scaffolder",
    email: gitAuthorInfo?.email ?? "scaffolder@backstage.io"
  };
  const commitHash = await git.commit({
    dir,
    message: commitMessage,
    author: authorInfo,
    committer: authorInfo
  });
  await git.addRemote({
    dir,
    url: remoteUrl,
    remote: "origin"
  });
  await git.push({
    dir,
    remote: "origin"
  });
  return { commitHash };
}
async function commitAndPushRepo(input) {
  const {
    dir,
    auth,
    logger,
    commitMessage,
    gitAuthorInfo,
    branch = "master",
    remoteRef
  } = input;
  const git = Git.fromAuth({
    ...auth,
    logger
  });
  await git.fetch({ dir });
  await git.checkout({ dir, ref: branch });
  await git.add({ dir, filepath: "." });
  const authorInfo = {
    name: gitAuthorInfo?.name ?? "Scaffolder",
    email: gitAuthorInfo?.email ?? "scaffolder@backstage.io"
  };
  const commitHash = await git.commit({
    dir,
    message: commitMessage,
    author: authorInfo,
    committer: authorInfo
  });
  await git.push({
    dir,
    remote: "origin",
    remoteRef: remoteRef ?? `refs/heads/${branch}`
  });
  return { commitHash };
}
async function cloneRepo(options) {
  const { url, dir, auth, logger, ref, depth, noCheckout } = options;
  const git = Git.fromAuth({
    ...auth,
    logger
  });
  await git.clone({ url, dir, ref, depth, noCheckout });
}
async function createBranch(options) {
  const { dir, ref, auth, logger } = options;
  const git = Git.fromAuth({
    ...auth,
    logger
  });
  await git.checkout({ dir, ref });
}
async function addFiles(options) {
  const { dir, filepath, auth, logger } = options;
  const git = Git.fromAuth({
    ...auth,
    logger
  });
  await git.add({ dir, filepath });
}
async function commitAndPushBranch(options) {
  const {
    dir,
    auth,
    logger,
    commitMessage,
    gitAuthorInfo,
    branch = "master",
    remoteRef,
    remote = "origin"
  } = options;
  const git = Git.fromAuth({
    ...auth,
    logger
  });
  const authorInfo = {
    name: gitAuthorInfo?.name ?? "Scaffolder",
    email: gitAuthorInfo?.email ?? "scaffolder@backstage.io"
  };
  const commitHash = await git.commit({
    dir,
    message: commitMessage,
    author: authorInfo,
    committer: authorInfo
  });
  await git.push({
    dir,
    remote,
    remoteRef: remoteRef ?? `refs/heads/${branch}`
  });
  return { commitHash };
}

const getRepoSourceDirectory = (workspacePath, sourcePath) => {
  if (sourcePath) {
    const safeSuffix = path.normalize(sourcePath).replace(
      /^(\.\.(\/|\\|$))+/,
      ""
    );
    const path$1 = path.join(workspacePath, safeSuffix);
    if (!backendPluginApi.isChildPath(workspacePath, path$1)) {
      throw new Error("Invalid source path");
    }
    return path$1;
  }
  return workspacePath;
};
const parseRepoUrl = (repoUrl, integrations) => {
  let parsed;
  try {
    parsed = new URL(`https://${repoUrl}`);
  } catch (error) {
    throw new errors.InputError(
      `Invalid repo URL passed to publisher, got ${repoUrl}, ${error}`
    );
  }
  const host = parsed.host;
  const owner = parsed.searchParams.get("owner") ?? void 0;
  const organization = parsed.searchParams.get("organization") ?? void 0;
  const workspace = parsed.searchParams.get("workspace") ?? void 0;
  const project = parsed.searchParams.get("project") ?? void 0;
  const type = integrations.byHost(host)?.type;
  if (!type) {
    throw new errors.InputError(
      `No matching integration configuration for host ${host}, please check your integrations config`
    );
  }
  const repo = parsed.searchParams.get("repo");
  switch (type) {
    case "bitbucket": {
      if (host === "www.bitbucket.org") {
        checkRequiredParams(parsed, "workspace");
      }
      checkRequiredParams(parsed, "project", "repo");
      break;
    }
    case "azure": {
      checkRequiredParams(parsed, "project", "repo");
      break;
    }
    case "gitlab": {
      if (!project) {
        checkRequiredParams(parsed, "owner", "repo");
      }
      break;
    }
    case "gitea": {
      checkRequiredParams(parsed, "repo");
      break;
    }
    case "gerrit": {
      checkRequiredParams(parsed, "repo");
      break;
    }
    default: {
      checkRequiredParams(parsed, "repo", "owner");
      break;
    }
  }
  return { host, owner, repo, organization, workspace, project };
};
function checkRequiredParams(repoUrl, ...params) {
  for (let i = 0; i < params.length; i++) {
    if (!repoUrl.searchParams.get(params[i])) {
      throw new errors.InputError(
        `Invalid repo URL passed to publisher: ${repoUrl.toString()}, missing ${params[i]}`
      );
    }
  }
}

const DEFAULT_GLOB_PATTERNS = ["./**", "!.git"];
const isExecutable = (fileMode) => {
  if (!fileMode) {
    return false;
  }
  const executeBitMask = 73;
  const res = fileMode & executeBitMask;
  return res > 0;
};
async function asyncFilter(array, callback) {
  const filterMap = await Promise.all(array.map(callback));
  return array.filter((_value, index) => filterMap[index]);
}
async function serializeDirectoryContents(sourcePath, options) {
  const paths = await globby__default.default(options?.globPatterns ?? DEFAULT_GLOB_PATTERNS, {
    cwd: sourcePath,
    dot: true,
    gitignore: options?.gitignore,
    followSymbolicLinks: false,
    // In order to pick up 'broken' symlinks, we oxymoronically request files AND folders yet we filter out folders
    // This is because broken symlinks aren't classed as files so we need to glob everything
    onlyFiles: false,
    objectMode: true,
    stats: true
  });
  const limiter = limiterFactory__default.default(10);
  const valid = await asyncFilter(paths, async ({ dirent, path }) => {
    if (dirent.isDirectory()) return false;
    if (!dirent.isSymbolicLink()) return true;
    const safePath = backendPluginApi.resolveSafeChildPath(sourcePath, path);
    try {
      await fs$1.promises.stat(safePath);
      return false;
    } catch (e) {
      return errors.isError(e) && e.code === "ENOENT";
    }
  });
  return Promise.all(
    valid.map(async ({ dirent, path, stats }) => ({
      path,
      content: await limiter(async () => {
        const absFilePath = backendPluginApi.resolveSafeChildPath(sourcePath, path);
        if (dirent.isSymbolicLink()) {
          return fs$1.promises.readlink(absFilePath, "buffer");
        }
        return fs$1.promises.readFile(absFilePath);
      }),
      executable: isExecutable(stats?.mode),
      symlink: dirent.isSymbolicLink()
    }))
  );
}

async function deserializeDirectoryContents(targetPath, files) {
  for (const file of files) {
    const filePath = backendPluginApi.resolveSafeChildPath(targetPath, file.path);
    await fs__default.default.ensureDir(path.dirname(filePath));
    await fs__default.default.writeFile(filePath, file.content);
  }
}

exports.addFiles = addFiles;
exports.cloneRepo = cloneRepo;
exports.commitAndPushBranch = commitAndPushBranch;
exports.commitAndPushRepo = commitAndPushRepo;
exports.createBranch = createBranch;
exports.createTemplateAction = createTemplateAction;
exports.deserializeDirectoryContents = deserializeDirectoryContents;
exports.executeShellCommand = executeShellCommand;
exports.fetchContents = fetchContents;
exports.fetchFile = fetchFile;
exports.getRepoSourceDirectory = getRepoSourceDirectory;
exports.initRepoAndPush = initRepoAndPush;
exports.parseRepoUrl = parseRepoUrl;
exports.serializeDirectoryContents = serializeDirectoryContents;
//# sourceMappingURL=index.cjs.js.map
